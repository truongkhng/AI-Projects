{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotions_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yY8jBr85owUSZ54tR741THjT4UythDaY",
      "authorship_tag": "ABX9TyMnxO/jbDef9UtIR+fJ4hIz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/truongkhng/AI-Projects/blob/main/Emotions_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LINK https://drive.google.com/drive/folders/1-Cs0pF3JZ4yrdq66bZyBX5GgOLP8OHp3?usp=sharing"
      ],
      "metadata": {
        "id": "qOh_2egYrPb0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import cv2\n",
        "from os import listdir\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "wbE6UjlKlSRH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_img_dataset(raw_folder,dataset_name):\n",
        "\n",
        "    target_size = (150, 150)\n",
        "    pictures = []\n",
        "    labels = []\n",
        "\n",
        "    for folder in listdir(raw_folder):\n",
        "      #print(\"Folder=\",folder)\n",
        "      for file in listdir(raw_folder + \"/\" + folder):\n",
        "        #print(\"File=\", file)\n",
        "        pictures.append(cv2.resize(cv2.imread((raw_folder + \"/\" + folder + \"/\" + file)\n",
        "        ,cv2.IMREAD_COLOR),dsize = target_size))\n",
        "        labels.append(folder)\n",
        "\n",
        "    pictures = np.array(pictures)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    encoder = LabelBinarizer()\n",
        "    labels = encoder.fit_transform(labels)\n",
        "\n",
        "    with open (dataset_name, mode = 'wb') as file:\n",
        "    # dump information to that file\n",
        "      pickle.dump((pictures,labels), file)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "def load_data(dataset_path):\n",
        "\n",
        "    file = open(dataset_path, mode = 'rb')\n",
        "    # dump information to that file\n",
        "    (pictures, labels) = pickle.load (file)\n",
        "    file.close()\n",
        "\n",
        "    return pictures, labels"
      ],
      "metadata": {
        "id": "rCOvbXVUt_Io"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_folder = \"/content/drive/MyDrive/Emotions\"\n",
        "\n",
        "create_img_dataset(raw_folder= raw_folder,dataset_name= 'emotions.txt')\n",
        "dataset_path = \"emotions.txt\"\n",
        "x_data,y_data = load_data(dataset_path= 'emotions.txt')\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split( x_data, y_data, test_size=0.2, random_state=100)"
      ],
      "metadata": {
        "id": "cArGdEOzuCmX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n"
      ],
      "metadata": {
        "id": "yIc7KVSJwgQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b5a324-c416-439e-8fcf-f090f81fb86e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1056, 150, 150, 3)\n",
            "(1056, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_original = x_test;\n",
        "y_test_original = y_test;\n",
        "x_label = ['Angry','Happy','Sad','Surprise']\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0"
      ],
      "metadata": {
        "id": "GPWCcfQJWoWk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add (Conv2D(32,(3,3),activation='relu',kernel_initializer='normal',padding='same',\n",
        "                  input_shape=(150,150,3)))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='normal',padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='normal',padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='normal',padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='normal',padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='normal',padding='same'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(MaxPool2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(32,activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(4,activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "wEfRhBpxHBUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(filepath= \"Emotions-weights-{epoch:02d}-{val_accuracy:.4f}.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
        "history = model.fit(x_train,y_train, epochs=500,batch_size = 32,validation_data=(x_test,y_test),verbose=1,callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "2P3e_98PHNMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f52a05e-9fd9-4304-c5f5-a26aac9dad28"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 2.0902 - accuracy: 0.3239\n",
            "Epoch 1: val_accuracy improved from -inf to 0.24621, saving model to Emotions-weights-01-0.2462.h5\n",
            "33/33 [==============================] - 56s 107ms/step - loss: 2.0902 - accuracy: 0.3239 - val_loss: 1.5157 - val_accuracy: 0.2462\n",
            "Epoch 2/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.3159 - accuracy: 0.4119\n",
            "Epoch 2: val_accuracy improved from 0.24621 to 0.28030, saving model to Emotions-weights-02-0.2803.h5\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 1.3159 - accuracy: 0.4119 - val_loss: 1.7378 - val_accuracy: 0.2803\n",
            "Epoch 3/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.2287 - accuracy: 0.4223\n",
            "Epoch 3: val_accuracy improved from 0.28030 to 0.31061, saving model to Emotions-weights-03-0.3106.h5\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 1.2287 - accuracy: 0.4223 - val_loss: 1.7710 - val_accuracy: 0.3106\n",
            "Epoch 4/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.1202 - accuracy: 0.5028\n",
            "Epoch 4: val_accuracy did not improve from 0.31061\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 1.1202 - accuracy: 0.5028 - val_loss: 1.7477 - val_accuracy: 0.2652\n",
            "Epoch 5/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.0961 - accuracy: 0.5104\n",
            "Epoch 5: val_accuracy did not improve from 0.31061\n",
            "33/33 [==============================] - 3s 86ms/step - loss: 1.0961 - accuracy: 0.5104 - val_loss: 1.6324 - val_accuracy: 0.2538\n",
            "Epoch 6/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 1.0082 - accuracy: 0.5502\n",
            "Epoch 6: val_accuracy did not improve from 0.31061\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 1.0082 - accuracy: 0.5502 - val_loss: 2.0501 - val_accuracy: 0.2727\n",
            "Epoch 7/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.9648 - accuracy: 0.5616\n",
            "Epoch 7: val_accuracy improved from 0.31061 to 0.35227, saving model to Emotions-weights-07-0.3523.h5\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.9648 - accuracy: 0.5616 - val_loss: 1.3089 - val_accuracy: 0.3523\n",
            "Epoch 8/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.9230 - accuracy: 0.6004\n",
            "Epoch 8: val_accuracy did not improve from 0.35227\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.9230 - accuracy: 0.6004 - val_loss: 1.8801 - val_accuracy: 0.2992\n",
            "Epoch 9/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.9204 - accuracy: 0.6117\n",
            "Epoch 9: val_accuracy did not improve from 0.35227\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.9204 - accuracy: 0.6117 - val_loss: 1.7153 - val_accuracy: 0.2689\n",
            "Epoch 10/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.7946 - accuracy: 0.6686\n",
            "Epoch 10: val_accuracy did not improve from 0.35227\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.7946 - accuracy: 0.6686 - val_loss: 1.8255 - val_accuracy: 0.3409\n",
            "Epoch 11/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.7875 - accuracy: 0.6714\n",
            "Epoch 11: val_accuracy improved from 0.35227 to 0.35985, saving model to Emotions-weights-11-0.3598.h5\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.7875 - accuracy: 0.6714 - val_loss: 2.1282 - val_accuracy: 0.3598\n",
            "Epoch 12/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.7099 - accuracy: 0.7008\n",
            "Epoch 12: val_accuracy improved from 0.35985 to 0.39394, saving model to Emotions-weights-12-0.3939.h5\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.7099 - accuracy: 0.7008 - val_loss: 1.5643 - val_accuracy: 0.3939\n",
            "Epoch 13/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6866 - accuracy: 0.7140\n",
            "Epoch 13: val_accuracy improved from 0.39394 to 0.44697, saving model to Emotions-weights-13-0.4470.h5\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.6866 - accuracy: 0.7140 - val_loss: 1.4681 - val_accuracy: 0.4470\n",
            "Epoch 14/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.7225\n",
            "Epoch 14: val_accuracy improved from 0.44697 to 0.50758, saving model to Emotions-weights-14-0.5076.h5\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.7011 - accuracy: 0.7225 - val_loss: 1.5295 - val_accuracy: 0.5076\n",
            "Epoch 15/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5900 - accuracy: 0.7491\n",
            "Epoch 15: val_accuracy did not improve from 0.50758\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.5900 - accuracy: 0.7491 - val_loss: 1.8932 - val_accuracy: 0.4659\n",
            "Epoch 16/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6110 - accuracy: 0.7538\n",
            "Epoch 16: val_accuracy did not improve from 0.50758\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.6110 - accuracy: 0.7538 - val_loss: 3.7410 - val_accuracy: 0.4129\n",
            "Epoch 17/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5950 - accuracy: 0.7680\n",
            "Epoch 17: val_accuracy did not improve from 0.50758\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.5950 - accuracy: 0.7680 - val_loss: 5.8809 - val_accuracy: 0.3561\n",
            "Epoch 18/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.7936\n",
            "Epoch 18: val_accuracy did not improve from 0.50758\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.5273 - accuracy: 0.7936 - val_loss: 1.7341 - val_accuracy: 0.4848\n",
            "Epoch 19/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.8134\n",
            "Epoch 19: val_accuracy did not improve from 0.50758\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.4785 - accuracy: 0.8134 - val_loss: 1.8250 - val_accuracy: 0.5038\n",
            "Epoch 20/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.8182\n",
            "Epoch 20: val_accuracy improved from 0.50758 to 0.61364, saving model to Emotions-weights-20-0.6136.h5\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.4568 - accuracy: 0.8182 - val_loss: 1.1001 - val_accuracy: 0.6136\n",
            "Epoch 21/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.8277\n",
            "Epoch 21: val_accuracy did not improve from 0.61364\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.4230 - accuracy: 0.8277 - val_loss: 1.2021 - val_accuracy: 0.5985\n",
            "Epoch 22/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.8343\n",
            "Epoch 22: val_accuracy did not improve from 0.61364\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.4408 - accuracy: 0.8343 - val_loss: 1.4132 - val_accuracy: 0.6023\n",
            "Epoch 23/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.8447\n",
            "Epoch 23: val_accuracy did not improve from 0.61364\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.3662 - accuracy: 0.8447 - val_loss: 1.5222 - val_accuracy: 0.5947\n",
            "Epoch 24/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.8807\n",
            "Epoch 24: val_accuracy improved from 0.61364 to 0.65909, saving model to Emotions-weights-24-0.6591.h5\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.3279 - accuracy: 0.8807 - val_loss: 0.9441 - val_accuracy: 0.6591\n",
            "Epoch 25/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.8920\n",
            "Epoch 25: val_accuracy improved from 0.65909 to 0.69318, saving model to Emotions-weights-25-0.6932.h5\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.2874 - accuracy: 0.8920 - val_loss: 0.9147 - val_accuracy: 0.6932\n",
            "Epoch 26/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.9138\n",
            "Epoch 26: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.2493 - accuracy: 0.9138 - val_loss: 1.1103 - val_accuracy: 0.6667\n",
            "Epoch 27/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.8873\n",
            "Epoch 27: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.2838 - accuracy: 0.8873 - val_loss: 0.9366 - val_accuracy: 0.6780\n",
            "Epoch 28/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.8930\n",
            "Epoch 28: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.2942 - accuracy: 0.8930 - val_loss: 2.3578 - val_accuracy: 0.5682\n",
            "Epoch 29/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.3649 - accuracy: 0.8617\n",
            "Epoch 29: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.3649 - accuracy: 0.8617 - val_loss: 1.1288 - val_accuracy: 0.6326\n",
            "Epoch 30/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9091\n",
            "Epoch 30: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.2465 - accuracy: 0.9091 - val_loss: 1.3527 - val_accuracy: 0.5985\n",
            "Epoch 31/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.9091\n",
            "Epoch 31: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.2323 - accuracy: 0.9091 - val_loss: 1.7794 - val_accuracy: 0.6174\n",
            "Epoch 32/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.9214\n",
            "Epoch 32: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.2187 - accuracy: 0.9214 - val_loss: 2.2070 - val_accuracy: 0.5038\n",
            "Epoch 33/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9015\n",
            "Epoch 33: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.2327 - accuracy: 0.9015 - val_loss: 5.8898 - val_accuracy: 0.3788\n",
            "Epoch 34/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.9091\n",
            "Epoch 34: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.2134 - accuracy: 0.9091 - val_loss: 6.0207 - val_accuracy: 0.4091\n",
            "Epoch 35/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.9366\n",
            "Epoch 35: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1807 - accuracy: 0.9366 - val_loss: 1.2472 - val_accuracy: 0.6667\n",
            "Epoch 36/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9328\n",
            "Epoch 36: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1694 - accuracy: 0.9328 - val_loss: 2.4193 - val_accuracy: 0.6061\n",
            "Epoch 37/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.9223\n",
            "Epoch 37: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.2284 - accuracy: 0.9223 - val_loss: 2.0402 - val_accuracy: 0.6288\n",
            "Epoch 38/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2313 - accuracy: 0.9129\n",
            "Epoch 38: val_accuracy did not improve from 0.69318\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.2313 - accuracy: 0.9129 - val_loss: 1.7739 - val_accuracy: 0.6477\n",
            "Epoch 39/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.9223\n",
            "Epoch 39: val_accuracy improved from 0.69318 to 0.71212, saving model to Emotions-weights-39-0.7121.h5\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.2179 - accuracy: 0.9223 - val_loss: 0.9031 - val_accuracy: 0.7121\n",
            "Epoch 40/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.9489\n",
            "Epoch 40: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.1517 - accuracy: 0.9489 - val_loss: 1.1270 - val_accuracy: 0.7083\n",
            "Epoch 41/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.9384\n",
            "Epoch 41: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1531 - accuracy: 0.9384 - val_loss: 0.9450 - val_accuracy: 0.7121\n",
            "Epoch 42/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9309\n",
            "Epoch 42: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.2007 - accuracy: 0.9309 - val_loss: 1.4167 - val_accuracy: 0.6515\n",
            "Epoch 43/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9337\n",
            "Epoch 43: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.2003 - accuracy: 0.9337 - val_loss: 1.2243 - val_accuracy: 0.6894\n",
            "Epoch 44/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9375\n",
            "Epoch 44: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1781 - accuracy: 0.9375 - val_loss: 1.5550 - val_accuracy: 0.6932\n",
            "Epoch 45/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9394\n",
            "Epoch 45: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1710 - accuracy: 0.9394 - val_loss: 1.0186 - val_accuracy: 0.6818\n",
            "Epoch 46/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9413\n",
            "Epoch 46: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1645 - accuracy: 0.9413 - val_loss: 1.4129 - val_accuracy: 0.6515\n",
            "Epoch 47/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.9384\n",
            "Epoch 47: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.1427 - accuracy: 0.9384 - val_loss: 1.3198 - val_accuracy: 0.6818\n",
            "Epoch 48/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.9583\n",
            "Epoch 48: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1232 - accuracy: 0.9583 - val_loss: 1.2067 - val_accuracy: 0.7083\n",
            "Epoch 49/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9508\n",
            "Epoch 49: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1328 - accuracy: 0.9508 - val_loss: 1.5094 - val_accuracy: 0.6970\n",
            "Epoch 50/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9545\n",
            "Epoch 50: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1497 - accuracy: 0.9545 - val_loss: 1.1789 - val_accuracy: 0.7083\n",
            "Epoch 51/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9290\n",
            "Epoch 51: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1945 - accuracy: 0.9290 - val_loss: 2.4469 - val_accuracy: 0.4886\n",
            "Epoch 52/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1625 - accuracy: 0.9460\n",
            "Epoch 52: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.1625 - accuracy: 0.9460 - val_loss: 2.1580 - val_accuracy: 0.5682\n",
            "Epoch 53/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.9517\n",
            "Epoch 53: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 98ms/step - loss: 0.1336 - accuracy: 0.9517 - val_loss: 3.6914 - val_accuracy: 0.4659\n",
            "Epoch 54/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9413\n",
            "Epoch 54: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1777 - accuracy: 0.9413 - val_loss: 3.3326 - val_accuracy: 0.5644\n",
            "Epoch 55/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9583\n",
            "Epoch 55: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.1221 - accuracy: 0.9583 - val_loss: 1.7847 - val_accuracy: 0.6439\n",
            "Epoch 56/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9470\n",
            "Epoch 56: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.1379 - accuracy: 0.9470 - val_loss: 1.6020 - val_accuracy: 0.6402\n",
            "Epoch 57/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9479\n",
            "Epoch 57: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.1281 - accuracy: 0.9479 - val_loss: 2.2987 - val_accuracy: 0.6023\n",
            "Epoch 58/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9583\n",
            "Epoch 58: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1064 - accuracy: 0.9583 - val_loss: 2.4270 - val_accuracy: 0.6591\n",
            "Epoch 59/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1146 - accuracy: 0.9602\n",
            "Epoch 59: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1146 - accuracy: 0.9602 - val_loss: 1.7425 - val_accuracy: 0.7045\n",
            "Epoch 60/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.9451\n",
            "Epoch 60: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.1662 - accuracy: 0.9451 - val_loss: 1.4091 - val_accuracy: 0.6970\n",
            "Epoch 61/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.9366\n",
            "Epoch 61: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1862 - accuracy: 0.9366 - val_loss: 2.3003 - val_accuracy: 0.6136\n",
            "Epoch 62/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.9669\n",
            "Epoch 62: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.1003 - accuracy: 0.9669 - val_loss: 3.6353 - val_accuracy: 0.5947\n",
            "Epoch 63/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9479\n",
            "Epoch 63: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1330 - accuracy: 0.9479 - val_loss: 2.4592 - val_accuracy: 0.5720\n",
            "Epoch 64/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9564\n",
            "Epoch 64: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1236 - accuracy: 0.9564 - val_loss: 1.3017 - val_accuracy: 0.6591\n",
            "Epoch 65/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9640\n",
            "Epoch 65: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0910 - accuracy: 0.9640 - val_loss: 1.6979 - val_accuracy: 0.6591\n",
            "Epoch 66/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9602\n",
            "Epoch 66: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1018 - accuracy: 0.9602 - val_loss: 2.1484 - val_accuracy: 0.6250\n",
            "Epoch 67/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9669\n",
            "Epoch 67: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1075 - accuracy: 0.9669 - val_loss: 1.7304 - val_accuracy: 0.6439\n",
            "Epoch 68/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9621\n",
            "Epoch 68: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1169 - accuracy: 0.9621 - val_loss: 1.4367 - val_accuracy: 0.6780\n",
            "Epoch 69/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.9602\n",
            "Epoch 69: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.1272 - accuracy: 0.9602 - val_loss: 3.2331 - val_accuracy: 0.5758\n",
            "Epoch 70/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1306 - accuracy: 0.9545\n",
            "Epoch 70: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1306 - accuracy: 0.9545 - val_loss: 1.4510 - val_accuracy: 0.6932\n",
            "Epoch 71/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9621\n",
            "Epoch 71: val_accuracy did not improve from 0.71212\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0885 - accuracy: 0.9621 - val_loss: 1.6485 - val_accuracy: 0.6856\n",
            "Epoch 72/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.9574\n",
            "Epoch 72: val_accuracy improved from 0.71212 to 0.72727, saving model to Emotions-weights-72-0.7273.h5\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.1038 - accuracy: 0.9574 - val_loss: 1.2606 - val_accuracy: 0.7273\n",
            "Epoch 73/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9631\n",
            "Epoch 73: val_accuracy did not improve from 0.72727\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1193 - accuracy: 0.9631 - val_loss: 1.2737 - val_accuracy: 0.6591\n",
            "Epoch 74/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9489\n",
            "Epoch 74: val_accuracy did not improve from 0.72727\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.1620 - accuracy: 0.9489 - val_loss: 1.9414 - val_accuracy: 0.5682\n",
            "Epoch 75/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.9631\n",
            "Epoch 75: val_accuracy did not improve from 0.72727\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0980 - accuracy: 0.9631 - val_loss: 1.1621 - val_accuracy: 0.7008\n",
            "Epoch 76/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9631\n",
            "Epoch 76: val_accuracy did not improve from 0.72727\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0999 - accuracy: 0.9631 - val_loss: 1.2647 - val_accuracy: 0.7045\n",
            "Epoch 77/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9631\n",
            "Epoch 77: val_accuracy did not improve from 0.72727\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1051 - accuracy: 0.9631 - val_loss: 1.2317 - val_accuracy: 0.7008\n",
            "Epoch 78/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9593\n",
            "Epoch 78: val_accuracy did not improve from 0.72727\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1160 - accuracy: 0.9593 - val_loss: 2.3956 - val_accuracy: 0.6136\n",
            "Epoch 79/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.9583\n",
            "Epoch 79: val_accuracy did not improve from 0.72727\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.1040 - accuracy: 0.9583 - val_loss: 1.2323 - val_accuracy: 0.6970\n",
            "Epoch 80/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9688\n",
            "Epoch 80: val_accuracy improved from 0.72727 to 0.73106, saving model to Emotions-weights-80-0.7311.h5\n",
            "33/33 [==============================] - 3s 95ms/step - loss: 0.0766 - accuracy: 0.9688 - val_loss: 1.0100 - val_accuracy: 0.7311\n",
            "Epoch 81/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9697\n",
            "Epoch 81: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0773 - accuracy: 0.9697 - val_loss: 2.0660 - val_accuracy: 0.6098\n",
            "Epoch 82/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.9706\n",
            "Epoch 82: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0977 - accuracy: 0.9706 - val_loss: 2.3039 - val_accuracy: 0.5871\n",
            "Epoch 83/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9754\n",
            "Epoch 83: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0545 - accuracy: 0.9754 - val_loss: 2.5817 - val_accuracy: 0.5871\n",
            "Epoch 84/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9688\n",
            "Epoch 84: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0860 - accuracy: 0.9688 - val_loss: 1.2910 - val_accuracy: 0.7045\n",
            "Epoch 85/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.9735\n",
            "Epoch 85: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0683 - accuracy: 0.9735 - val_loss: 1.5379 - val_accuracy: 0.6932\n",
            "Epoch 86/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9593\n",
            "Epoch 86: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1075 - accuracy: 0.9593 - val_loss: 2.0190 - val_accuracy: 0.6515\n",
            "Epoch 87/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9716\n",
            "Epoch 87: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0787 - accuracy: 0.9716 - val_loss: 4.9942 - val_accuracy: 0.4697\n",
            "Epoch 88/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9706\n",
            "Epoch 88: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0658 - accuracy: 0.9706 - val_loss: 1.9183 - val_accuracy: 0.6932\n",
            "Epoch 89/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9763\n",
            "Epoch 89: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0735 - accuracy: 0.9763 - val_loss: 1.2696 - val_accuracy: 0.7273\n",
            "Epoch 90/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9706\n",
            "Epoch 90: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0746 - accuracy: 0.9706 - val_loss: 1.5597 - val_accuracy: 0.6705\n",
            "Epoch 91/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9706\n",
            "Epoch 91: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0802 - accuracy: 0.9706 - val_loss: 2.3800 - val_accuracy: 0.5985\n",
            "Epoch 92/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9640\n",
            "Epoch 92: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.1212 - accuracy: 0.9640 - val_loss: 1.5278 - val_accuracy: 0.6856\n",
            "Epoch 93/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9545\n",
            "Epoch 93: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1172 - accuracy: 0.9545 - val_loss: 1.2937 - val_accuracy: 0.6515\n",
            "Epoch 94/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9659\n",
            "Epoch 94: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1021 - accuracy: 0.9659 - val_loss: 2.1993 - val_accuracy: 0.6174\n",
            "Epoch 95/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9744\n",
            "Epoch 95: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0605 - accuracy: 0.9744 - val_loss: 3.7129 - val_accuracy: 0.4811\n",
            "Epoch 96/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 0.9688\n",
            "Epoch 96: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0947 - accuracy: 0.9688 - val_loss: 2.8218 - val_accuracy: 0.6098\n",
            "Epoch 97/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9697\n",
            "Epoch 97: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0880 - accuracy: 0.9697 - val_loss: 1.4750 - val_accuracy: 0.6894\n",
            "Epoch 98/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9716\n",
            "Epoch 98: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0848 - accuracy: 0.9716 - val_loss: 1.7306 - val_accuracy: 0.6856\n",
            "Epoch 99/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9659\n",
            "Epoch 99: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.1096 - accuracy: 0.9659 - val_loss: 1.3794 - val_accuracy: 0.6742\n",
            "Epoch 100/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9621\n",
            "Epoch 100: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1078 - accuracy: 0.9621 - val_loss: 1.4632 - val_accuracy: 0.7045\n",
            "Epoch 101/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9754\n",
            "Epoch 101: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0784 - accuracy: 0.9754 - val_loss: 2.3947 - val_accuracy: 0.6364\n",
            "Epoch 102/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9640\n",
            "Epoch 102: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0933 - accuracy: 0.9640 - val_loss: 1.3678 - val_accuracy: 0.7121\n",
            "Epoch 103/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9773\n",
            "Epoch 103: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0784 - accuracy: 0.9773 - val_loss: 1.6849 - val_accuracy: 0.6629\n",
            "Epoch 104/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9650\n",
            "Epoch 104: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1300 - accuracy: 0.9650 - val_loss: 1.9307 - val_accuracy: 0.6780\n",
            "Epoch 105/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9669\n",
            "Epoch 105: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1077 - accuracy: 0.9669 - val_loss: 1.2211 - val_accuracy: 0.7273\n",
            "Epoch 106/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9697\n",
            "Epoch 106: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0869 - accuracy: 0.9697 - val_loss: 1.6160 - val_accuracy: 0.6553\n",
            "Epoch 107/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.9659\n",
            "Epoch 107: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0820 - accuracy: 0.9659 - val_loss: 1.5980 - val_accuracy: 0.6705\n",
            "Epoch 108/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9716\n",
            "Epoch 108: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0780 - accuracy: 0.9716 - val_loss: 2.3112 - val_accuracy: 0.6023\n",
            "Epoch 109/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9735\n",
            "Epoch 109: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0804 - accuracy: 0.9735 - val_loss: 1.4505 - val_accuracy: 0.6970\n",
            "Epoch 110/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9697\n",
            "Epoch 110: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0798 - accuracy: 0.9697 - val_loss: 2.1638 - val_accuracy: 0.5947\n",
            "Epoch 111/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0927 - accuracy: 0.9706\n",
            "Epoch 111: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0927 - accuracy: 0.9706 - val_loss: 2.0428 - val_accuracy: 0.6364\n",
            "Epoch 112/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9830\n",
            "Epoch 112: val_accuracy did not improve from 0.73106\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0480 - accuracy: 0.9830 - val_loss: 1.5238 - val_accuracy: 0.6856\n",
            "Epoch 113/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9886\n",
            "Epoch 113: val_accuracy improved from 0.73106 to 0.76515, saving model to Emotions-weights-113-0.7652.h5\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0388 - accuracy: 0.9886 - val_loss: 1.2129 - val_accuracy: 0.7652\n",
            "Epoch 114/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9801\n",
            "Epoch 114: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0587 - accuracy: 0.9801 - val_loss: 2.0211 - val_accuracy: 0.6742\n",
            "Epoch 115/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9744\n",
            "Epoch 115: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0613 - accuracy: 0.9744 - val_loss: 1.5629 - val_accuracy: 0.7197\n",
            "Epoch 116/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.9820\n",
            "Epoch 116: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0484 - accuracy: 0.9820 - val_loss: 1.3397 - val_accuracy: 0.7159\n",
            "Epoch 117/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9811\n",
            "Epoch 117: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0572 - accuracy: 0.9811 - val_loss: 2.8230 - val_accuracy: 0.6326\n",
            "Epoch 118/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9839\n",
            "Epoch 118: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 1.5215 - val_accuracy: 0.7045\n",
            "Epoch 119/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9754\n",
            "Epoch 119: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0635 - accuracy: 0.9754 - val_loss: 1.7154 - val_accuracy: 0.6742\n",
            "Epoch 120/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9820\n",
            "Epoch 120: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0471 - accuracy: 0.9820 - val_loss: 2.2233 - val_accuracy: 0.6098\n",
            "Epoch 121/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9830\n",
            "Epoch 121: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0536 - accuracy: 0.9830 - val_loss: 1.2997 - val_accuracy: 0.7273\n",
            "Epoch 122/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9716\n",
            "Epoch 122: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0682 - accuracy: 0.9716 - val_loss: 1.7076 - val_accuracy: 0.6894\n",
            "Epoch 123/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9782\n",
            "Epoch 123: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0635 - accuracy: 0.9782 - val_loss: 1.2856 - val_accuracy: 0.7008\n",
            "Epoch 124/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9867\n",
            "Epoch 124: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0401 - accuracy: 0.9867 - val_loss: 1.3739 - val_accuracy: 0.7273\n",
            "Epoch 125/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.9792\n",
            "Epoch 125: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0596 - accuracy: 0.9792 - val_loss: 1.3003 - val_accuracy: 0.7424\n",
            "Epoch 126/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9782\n",
            "Epoch 126: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0513 - accuracy: 0.9782 - val_loss: 2.0325 - val_accuracy: 0.6856\n",
            "Epoch 127/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9773\n",
            "Epoch 127: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0473 - accuracy: 0.9773 - val_loss: 1.5726 - val_accuracy: 0.7348\n",
            "Epoch 128/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9782\n",
            "Epoch 128: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0719 - accuracy: 0.9782 - val_loss: 2.1271 - val_accuracy: 0.6780\n",
            "Epoch 129/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9782\n",
            "Epoch 129: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0882 - accuracy: 0.9782 - val_loss: 2.0808 - val_accuracy: 0.6288\n",
            "Epoch 130/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9801\n",
            "Epoch 130: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0513 - accuracy: 0.9801 - val_loss: 1.4422 - val_accuracy: 0.7159\n",
            "Epoch 131/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9830\n",
            "Epoch 131: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0369 - accuracy: 0.9830 - val_loss: 1.3415 - val_accuracy: 0.7576\n",
            "Epoch 132/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9915\n",
            "Epoch 132: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0315 - accuracy: 0.9915 - val_loss: 1.4259 - val_accuracy: 0.7386\n",
            "Epoch 133/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9763\n",
            "Epoch 133: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0788 - accuracy: 0.9763 - val_loss: 2.9545 - val_accuracy: 0.5227\n",
            "Epoch 134/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9811\n",
            "Epoch 134: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 1.9215 - val_accuracy: 0.6894\n",
            "Epoch 135/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.9744\n",
            "Epoch 135: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0688 - accuracy: 0.9744 - val_loss: 1.2021 - val_accuracy: 0.7424\n",
            "Epoch 136/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9763\n",
            "Epoch 136: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0691 - accuracy: 0.9763 - val_loss: 2.0322 - val_accuracy: 0.6477\n",
            "Epoch 137/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1075 - accuracy: 0.9612\n",
            "Epoch 137: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.1075 - accuracy: 0.9612 - val_loss: 2.2287 - val_accuracy: 0.6364\n",
            "Epoch 138/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9792\n",
            "Epoch 138: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0557 - accuracy: 0.9792 - val_loss: 1.6430 - val_accuracy: 0.6932\n",
            "Epoch 139/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9792\n",
            "Epoch 139: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0735 - accuracy: 0.9792 - val_loss: 1.4318 - val_accuracy: 0.6894\n",
            "Epoch 140/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9867\n",
            "Epoch 140: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0473 - accuracy: 0.9867 - val_loss: 2.9279 - val_accuracy: 0.5720\n",
            "Epoch 141/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9782\n",
            "Epoch 141: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0652 - accuracy: 0.9782 - val_loss: 1.3983 - val_accuracy: 0.7235\n",
            "Epoch 142/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9811\n",
            "Epoch 142: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0592 - accuracy: 0.9811 - val_loss: 1.4603 - val_accuracy: 0.7348\n",
            "Epoch 143/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9763\n",
            "Epoch 143: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0689 - accuracy: 0.9763 - val_loss: 1.5632 - val_accuracy: 0.7197\n",
            "Epoch 144/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.9773\n",
            "Epoch 144: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0679 - accuracy: 0.9773 - val_loss: 1.3735 - val_accuracy: 0.7083\n",
            "Epoch 145/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.9754\n",
            "Epoch 145: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0687 - accuracy: 0.9754 - val_loss: 1.7262 - val_accuracy: 0.7083\n",
            "Epoch 146/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9801\n",
            "Epoch 146: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0567 - accuracy: 0.9801 - val_loss: 1.6488 - val_accuracy: 0.7197\n",
            "Epoch 147/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9763\n",
            "Epoch 147: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0828 - accuracy: 0.9763 - val_loss: 4.4419 - val_accuracy: 0.5265\n",
            "Epoch 148/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9716\n",
            "Epoch 148: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0985 - accuracy: 0.9716 - val_loss: 1.9556 - val_accuracy: 0.6477\n",
            "Epoch 149/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9706\n",
            "Epoch 149: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0939 - accuracy: 0.9706 - val_loss: 2.9597 - val_accuracy: 0.5871\n",
            "Epoch 150/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9650\n",
            "Epoch 150: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.1156 - accuracy: 0.9650 - val_loss: 2.6185 - val_accuracy: 0.5947\n",
            "Epoch 151/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9782\n",
            "Epoch 151: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0704 - accuracy: 0.9782 - val_loss: 2.0036 - val_accuracy: 0.6780\n",
            "Epoch 152/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9896\n",
            "Epoch 152: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 1.4251 - val_accuracy: 0.7235\n",
            "Epoch 153/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9754\n",
            "Epoch 153: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0676 - accuracy: 0.9754 - val_loss: 2.0537 - val_accuracy: 0.6742\n",
            "Epoch 154/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9886\n",
            "Epoch 154: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0332 - accuracy: 0.9886 - val_loss: 1.8575 - val_accuracy: 0.6705\n",
            "Epoch 155/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9877\n",
            "Epoch 155: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 1.5388 - val_accuracy: 0.7159\n",
            "Epoch 156/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9801\n",
            "Epoch 156: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0593 - accuracy: 0.9801 - val_loss: 1.9450 - val_accuracy: 0.6629\n",
            "Epoch 157/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9792\n",
            "Epoch 157: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0601 - accuracy: 0.9792 - val_loss: 2.7561 - val_accuracy: 0.6288\n",
            "Epoch 158/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9801\n",
            "Epoch 158: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0600 - accuracy: 0.9801 - val_loss: 2.3930 - val_accuracy: 0.6477\n",
            "Epoch 159/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9801\n",
            "Epoch 159: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0466 - accuracy: 0.9801 - val_loss: 1.1673 - val_accuracy: 0.7311\n",
            "Epoch 160/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9811\n",
            "Epoch 160: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0494 - accuracy: 0.9811 - val_loss: 1.1280 - val_accuracy: 0.7386\n",
            "Epoch 161/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9848\n",
            "Epoch 161: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0418 - accuracy: 0.9848 - val_loss: 1.1913 - val_accuracy: 0.7424\n",
            "Epoch 162/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9830\n",
            "Epoch 162: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0408 - accuracy: 0.9830 - val_loss: 1.5365 - val_accuracy: 0.6856\n",
            "Epoch 163/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9820\n",
            "Epoch 163: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0455 - accuracy: 0.9820 - val_loss: 3.1103 - val_accuracy: 0.5303\n",
            "Epoch 164/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9877\n",
            "Epoch 164: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0392 - accuracy: 0.9877 - val_loss: 1.3320 - val_accuracy: 0.7311\n",
            "Epoch 165/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9877\n",
            "Epoch 165: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0324 - accuracy: 0.9877 - val_loss: 1.5921 - val_accuracy: 0.7348\n",
            "Epoch 166/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.9811\n",
            "Epoch 166: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0569 - accuracy: 0.9811 - val_loss: 1.6006 - val_accuracy: 0.7311\n",
            "Epoch 167/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9858\n",
            "Epoch 167: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0406 - accuracy: 0.9858 - val_loss: 1.9881 - val_accuracy: 0.6818\n",
            "Epoch 168/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9782\n",
            "Epoch 168: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0515 - accuracy: 0.9782 - val_loss: 1.5100 - val_accuracy: 0.7159\n",
            "Epoch 169/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9867\n",
            "Epoch 169: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 1.7219 - val_accuracy: 0.6970\n",
            "Epoch 170/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9886\n",
            "Epoch 170: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 2.1058 - val_accuracy: 0.6742\n",
            "Epoch 171/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9915\n",
            "Epoch 171: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 2.0844 - val_accuracy: 0.6894\n",
            "Epoch 172/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9877\n",
            "Epoch 172: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0293 - accuracy: 0.9877 - val_loss: 1.5537 - val_accuracy: 0.7538\n",
            "Epoch 173/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9782\n",
            "Epoch 173: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0689 - accuracy: 0.9782 - val_loss: 3.7057 - val_accuracy: 0.6288\n",
            "Epoch 174/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9848\n",
            "Epoch 174: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0460 - accuracy: 0.9848 - val_loss: 4.6270 - val_accuracy: 0.5114\n",
            "Epoch 175/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9744\n",
            "Epoch 175: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0745 - accuracy: 0.9744 - val_loss: 3.1071 - val_accuracy: 0.5720\n",
            "Epoch 176/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9744\n",
            "Epoch 176: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0802 - accuracy: 0.9744 - val_loss: 2.3369 - val_accuracy: 0.6970\n",
            "Epoch 177/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9706\n",
            "Epoch 177: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0815 - accuracy: 0.9706 - val_loss: 2.6541 - val_accuracy: 0.6250\n",
            "Epoch 178/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9811\n",
            "Epoch 178: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0505 - accuracy: 0.9811 - val_loss: 1.4398 - val_accuracy: 0.7045\n",
            "Epoch 179/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9839\n",
            "Epoch 179: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0460 - accuracy: 0.9839 - val_loss: 1.4706 - val_accuracy: 0.6932\n",
            "Epoch 180/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.9848\n",
            "Epoch 180: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0381 - accuracy: 0.9848 - val_loss: 1.6554 - val_accuracy: 0.7197\n",
            "Epoch 181/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9877\n",
            "Epoch 181: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0482 - accuracy: 0.9877 - val_loss: 1.3290 - val_accuracy: 0.7386\n",
            "Epoch 182/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9811\n",
            "Epoch 182: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0446 - accuracy: 0.9811 - val_loss: 2.0702 - val_accuracy: 0.7121\n",
            "Epoch 183/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.9839\n",
            "Epoch 183: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0435 - accuracy: 0.9839 - val_loss: 2.0206 - val_accuracy: 0.6970\n",
            "Epoch 184/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9858\n",
            "Epoch 184: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0326 - accuracy: 0.9858 - val_loss: 2.4569 - val_accuracy: 0.6932\n",
            "Epoch 185/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9896\n",
            "Epoch 185: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0247 - accuracy: 0.9896 - val_loss: 1.9509 - val_accuracy: 0.7348\n",
            "Epoch 186/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9905\n",
            "Epoch 186: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0235 - accuracy: 0.9905 - val_loss: 1.7964 - val_accuracy: 0.7348\n",
            "Epoch 187/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9858\n",
            "Epoch 187: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0311 - accuracy: 0.9858 - val_loss: 2.5956 - val_accuracy: 0.6780\n",
            "Epoch 188/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9867\n",
            "Epoch 188: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0362 - accuracy: 0.9867 - val_loss: 1.6633 - val_accuracy: 0.7348\n",
            "Epoch 189/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9896\n",
            "Epoch 189: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 2.4373 - val_accuracy: 0.6742\n",
            "Epoch 190/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9839\n",
            "Epoch 190: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0455 - accuracy: 0.9839 - val_loss: 3.4132 - val_accuracy: 0.6136\n",
            "Epoch 191/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 0.9792\n",
            "Epoch 191: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0644 - accuracy: 0.9792 - val_loss: 6.2917 - val_accuracy: 0.4924\n",
            "Epoch 192/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9830\n",
            "Epoch 192: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0547 - accuracy: 0.9830 - val_loss: 1.7936 - val_accuracy: 0.6970\n",
            "Epoch 193/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.9848\n",
            "Epoch 193: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0445 - accuracy: 0.9848 - val_loss: 2.3161 - val_accuracy: 0.6591\n",
            "Epoch 194/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9773\n",
            "Epoch 194: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0738 - accuracy: 0.9773 - val_loss: 1.4079 - val_accuracy: 0.6970\n",
            "Epoch 195/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.9839\n",
            "Epoch 195: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0633 - accuracy: 0.9839 - val_loss: 3.4170 - val_accuracy: 0.5795\n",
            "Epoch 196/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9848\n",
            "Epoch 196: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0500 - accuracy: 0.9848 - val_loss: 1.3554 - val_accuracy: 0.7348\n",
            "Epoch 197/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 0.9886\n",
            "Epoch 197: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0326 - accuracy: 0.9886 - val_loss: 1.9427 - val_accuracy: 0.6818\n",
            "Epoch 198/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9877\n",
            "Epoch 198: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 2.3400 - val_accuracy: 0.6402\n",
            "Epoch 199/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9801\n",
            "Epoch 199: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0587 - accuracy: 0.9801 - val_loss: 1.2130 - val_accuracy: 0.7538\n",
            "Epoch 200/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9915\n",
            "Epoch 200: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0234 - accuracy: 0.9915 - val_loss: 1.2457 - val_accuracy: 0.7614\n",
            "Epoch 201/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9801\n",
            "Epoch 201: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0485 - accuracy: 0.9801 - val_loss: 1.2969 - val_accuracy: 0.7159\n",
            "Epoch 202/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9867\n",
            "Epoch 202: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0335 - accuracy: 0.9867 - val_loss: 1.9023 - val_accuracy: 0.6705\n",
            "Epoch 203/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9820\n",
            "Epoch 203: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0425 - accuracy: 0.9820 - val_loss: 2.0594 - val_accuracy: 0.7045\n",
            "Epoch 204/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9886\n",
            "Epoch 204: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0297 - accuracy: 0.9886 - val_loss: 2.8540 - val_accuracy: 0.6439\n",
            "Epoch 205/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9811\n",
            "Epoch 205: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0705 - accuracy: 0.9811 - val_loss: 1.4092 - val_accuracy: 0.7159\n",
            "Epoch 206/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9915\n",
            "Epoch 206: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0222 - accuracy: 0.9915 - val_loss: 2.0212 - val_accuracy: 0.6818\n",
            "Epoch 207/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9943\n",
            "Epoch 207: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 2.1106 - val_accuracy: 0.7045\n",
            "Epoch 208/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9896\n",
            "Epoch 208: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 3.2665 - val_accuracy: 0.5871\n",
            "Epoch 209/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9905\n",
            "Epoch 209: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 2.3702 - val_accuracy: 0.6515\n",
            "Epoch 210/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9905\n",
            "Epoch 210: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 1.6281 - val_accuracy: 0.7348\n",
            "Epoch 211/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9924\n",
            "Epoch 211: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 1.6827 - val_accuracy: 0.6970\n",
            "Epoch 212/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9915\n",
            "Epoch 212: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 1.8084 - val_accuracy: 0.7159\n",
            "Epoch 213/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9953\n",
            "Epoch 213: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 1.6633 - val_accuracy: 0.7348\n",
            "Epoch 214/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.9867\n",
            "Epoch 214: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0377 - accuracy: 0.9867 - val_loss: 1.4650 - val_accuracy: 0.7386\n",
            "Epoch 215/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9896\n",
            "Epoch 215: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0378 - accuracy: 0.9896 - val_loss: 1.5690 - val_accuracy: 0.6970\n",
            "Epoch 216/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9867\n",
            "Epoch 216: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0353 - accuracy: 0.9867 - val_loss: 1.5819 - val_accuracy: 0.7159\n",
            "Epoch 217/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9896\n",
            "Epoch 217: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 1.4782 - val_accuracy: 0.7159\n",
            "Epoch 218/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9915\n",
            "Epoch 218: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 1.3976 - val_accuracy: 0.7311\n",
            "Epoch 219/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9896\n",
            "Epoch 219: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0251 - accuracy: 0.9896 - val_loss: 1.3478 - val_accuracy: 0.7614\n",
            "Epoch 220/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9915\n",
            "Epoch 220: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 2.8668 - val_accuracy: 0.6780\n",
            "Epoch 221/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9792\n",
            "Epoch 221: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0686 - accuracy: 0.9792 - val_loss: 1.5473 - val_accuracy: 0.7045\n",
            "Epoch 222/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9867\n",
            "Epoch 222: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0476 - accuracy: 0.9867 - val_loss: 1.7337 - val_accuracy: 0.7045\n",
            "Epoch 223/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9867\n",
            "Epoch 223: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0425 - accuracy: 0.9867 - val_loss: 1.6834 - val_accuracy: 0.7159\n",
            "Epoch 224/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.9830\n",
            "Epoch 224: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0505 - accuracy: 0.9830 - val_loss: 2.6919 - val_accuracy: 0.6402\n",
            "Epoch 225/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9867\n",
            "Epoch 225: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0349 - accuracy: 0.9867 - val_loss: 1.5885 - val_accuracy: 0.7083\n",
            "Epoch 226/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9896\n",
            "Epoch 226: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0574 - accuracy: 0.9896 - val_loss: 1.2806 - val_accuracy: 0.7311\n",
            "Epoch 227/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9848\n",
            "Epoch 227: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0372 - accuracy: 0.9848 - val_loss: 1.4417 - val_accuracy: 0.7235\n",
            "Epoch 228/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0384 - accuracy: 0.9867\n",
            "Epoch 228: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 2.3753 - val_accuracy: 0.6742\n",
            "Epoch 229/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9886\n",
            "Epoch 229: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0390 - accuracy: 0.9886 - val_loss: 2.8475 - val_accuracy: 0.6250\n",
            "Epoch 230/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9886\n",
            "Epoch 230: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0321 - accuracy: 0.9886 - val_loss: 2.0892 - val_accuracy: 0.6932\n",
            "Epoch 231/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9886\n",
            "Epoch 231: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0269 - accuracy: 0.9886 - val_loss: 2.0666 - val_accuracy: 0.6970\n",
            "Epoch 232/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9782\n",
            "Epoch 232: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0810 - accuracy: 0.9782 - val_loss: 2.9828 - val_accuracy: 0.6629\n",
            "Epoch 233/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9811\n",
            "Epoch 233: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0800 - accuracy: 0.9811 - val_loss: 4.4898 - val_accuracy: 0.5379\n",
            "Epoch 234/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9924\n",
            "Epoch 234: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0291 - accuracy: 0.9924 - val_loss: 3.7808 - val_accuracy: 0.5795\n",
            "Epoch 235/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9801\n",
            "Epoch 235: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0499 - accuracy: 0.9801 - val_loss: 2.3399 - val_accuracy: 0.6742\n",
            "Epoch 236/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9886\n",
            "Epoch 236: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.0416 - accuracy: 0.9886 - val_loss: 2.1148 - val_accuracy: 0.6591\n",
            "Epoch 237/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9915\n",
            "Epoch 237: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 1.4354 - val_accuracy: 0.7273\n",
            "Epoch 238/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9858\n",
            "Epoch 238: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0359 - accuracy: 0.9858 - val_loss: 2.2745 - val_accuracy: 0.7045\n",
            "Epoch 239/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9943\n",
            "Epoch 239: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0126 - accuracy: 0.9943 - val_loss: 2.3150 - val_accuracy: 0.6742\n",
            "Epoch 240/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9915\n",
            "Epoch 240: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0287 - accuracy: 0.9915 - val_loss: 1.3436 - val_accuracy: 0.7462\n",
            "Epoch 241/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9886\n",
            "Epoch 241: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0257 - accuracy: 0.9886 - val_loss: 1.4100 - val_accuracy: 0.7348\n",
            "Epoch 242/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9915\n",
            "Epoch 242: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0157 - accuracy: 0.9915 - val_loss: 1.3511 - val_accuracy: 0.7538\n",
            "Epoch 243/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9886\n",
            "Epoch 243: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0339 - accuracy: 0.9886 - val_loss: 1.4667 - val_accuracy: 0.7235\n",
            "Epoch 244/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9924\n",
            "Epoch 244: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 1.8915 - val_accuracy: 0.6818\n",
            "Epoch 245/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9877\n",
            "Epoch 245: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 2.1424 - val_accuracy: 0.6894\n",
            "Epoch 246/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9924\n",
            "Epoch 246: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 1.6285 - val_accuracy: 0.7462\n",
            "Epoch 247/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9848\n",
            "Epoch 247: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0415 - accuracy: 0.9848 - val_loss: 1.6441 - val_accuracy: 0.7424\n",
            "Epoch 248/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9877\n",
            "Epoch 248: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0350 - accuracy: 0.9877 - val_loss: 2.3374 - val_accuracy: 0.6326\n",
            "Epoch 249/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9867\n",
            "Epoch 249: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0352 - accuracy: 0.9867 - val_loss: 1.4151 - val_accuracy: 0.7576\n",
            "Epoch 250/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9915\n",
            "Epoch 250: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0322 - accuracy: 0.9915 - val_loss: 2.1360 - val_accuracy: 0.6856\n",
            "Epoch 251/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9905\n",
            "Epoch 251: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0457 - accuracy: 0.9905 - val_loss: 1.4402 - val_accuracy: 0.7348\n",
            "Epoch 252/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9896\n",
            "Epoch 252: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0436 - accuracy: 0.9896 - val_loss: 1.5653 - val_accuracy: 0.7500\n",
            "Epoch 253/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9924\n",
            "Epoch 253: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0208 - accuracy: 0.9924 - val_loss: 1.5285 - val_accuracy: 0.7614\n",
            "Epoch 254/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9877\n",
            "Epoch 254: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0339 - accuracy: 0.9877 - val_loss: 1.5767 - val_accuracy: 0.7235\n",
            "Epoch 255/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9962\n",
            "Epoch 255: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0096 - accuracy: 0.9962 - val_loss: 1.5872 - val_accuracy: 0.7197\n",
            "Epoch 256/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9877\n",
            "Epoch 256: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0268 - accuracy: 0.9877 - val_loss: 1.3133 - val_accuracy: 0.7462\n",
            "Epoch 257/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9915\n",
            "Epoch 257: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0408 - accuracy: 0.9915 - val_loss: 1.7405 - val_accuracy: 0.6894\n",
            "Epoch 258/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9867\n",
            "Epoch 258: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0589 - accuracy: 0.9867 - val_loss: 1.7502 - val_accuracy: 0.6970\n",
            "Epoch 259/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9915\n",
            "Epoch 259: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0316 - accuracy: 0.9915 - val_loss: 2.0775 - val_accuracy: 0.6818\n",
            "Epoch 260/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9924\n",
            "Epoch 260: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0263 - accuracy: 0.9924 - val_loss: 2.1088 - val_accuracy: 0.6894\n",
            "Epoch 261/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9943\n",
            "Epoch 261: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 1.5825 - val_accuracy: 0.7538\n",
            "Epoch 262/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9886\n",
            "Epoch 262: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0259 - accuracy: 0.9886 - val_loss: 2.3351 - val_accuracy: 0.6174\n",
            "Epoch 263/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9896\n",
            "Epoch 263: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 2.7509 - val_accuracy: 0.5758\n",
            "Epoch 264/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9943\n",
            "Epoch 264: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0214 - accuracy: 0.9943 - val_loss: 1.5577 - val_accuracy: 0.7083\n",
            "Epoch 265/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9915\n",
            "Epoch 265: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 1.1549 - val_accuracy: 0.7311\n",
            "Epoch 266/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9867\n",
            "Epoch 266: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0264 - accuracy: 0.9867 - val_loss: 1.1153 - val_accuracy: 0.7614\n",
            "Epoch 267/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9953\n",
            "Epoch 267: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 1.3557 - val_accuracy: 0.7424\n",
            "Epoch 268/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9943\n",
            "Epoch 268: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 1.4654 - val_accuracy: 0.7273\n",
            "Epoch 269/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9924\n",
            "Epoch 269: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0194 - accuracy: 0.9924 - val_loss: 1.8497 - val_accuracy: 0.7008\n",
            "Epoch 270/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9981\n",
            "Epoch 270: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 1.5387 - val_accuracy: 0.7424\n",
            "Epoch 271/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9943\n",
            "Epoch 271: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 2.3136 - val_accuracy: 0.6553\n",
            "Epoch 272/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9934\n",
            "Epoch 272: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0160 - accuracy: 0.9934 - val_loss: 1.5158 - val_accuracy: 0.7652\n",
            "Epoch 273/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9915\n",
            "Epoch 273: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0320 - accuracy: 0.9915 - val_loss: 1.6167 - val_accuracy: 0.7311\n",
            "Epoch 274/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9924\n",
            "Epoch 274: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0138 - accuracy: 0.9924 - val_loss: 1.7233 - val_accuracy: 0.7121\n",
            "Epoch 275/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9924\n",
            "Epoch 275: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0177 - accuracy: 0.9924 - val_loss: 1.5645 - val_accuracy: 0.7159\n",
            "Epoch 276/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9943\n",
            "Epoch 276: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 1.4712 - val_accuracy: 0.7348\n",
            "Epoch 277/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9943\n",
            "Epoch 277: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0144 - accuracy: 0.9943 - val_loss: 1.7909 - val_accuracy: 0.7235\n",
            "Epoch 278/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9905\n",
            "Epoch 278: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0246 - accuracy: 0.9905 - val_loss: 1.5727 - val_accuracy: 0.7348\n",
            "Epoch 279/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9972\n",
            "Epoch 279: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0164 - accuracy: 0.9972 - val_loss: 1.7253 - val_accuracy: 0.7500\n",
            "Epoch 280/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9962\n",
            "Epoch 280: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 1.3837 - val_accuracy: 0.7652\n",
            "Epoch 281/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9962\n",
            "Epoch 281: val_accuracy did not improve from 0.76515\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 1.6097 - val_accuracy: 0.7348\n",
            "Epoch 282/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9943\n",
            "Epoch 282: val_accuracy improved from 0.76515 to 0.78030, saving model to Emotions-weights-282-0.7803.h5\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 1.4083 - val_accuracy: 0.7803\n",
            "Epoch 283/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9953\n",
            "Epoch 283: val_accuracy improved from 0.78030 to 0.79545, saving model to Emotions-weights-283-0.7955.h5\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 1.3245 - val_accuracy: 0.7955\n",
            "Epoch 284/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9934\n",
            "Epoch 284: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 3.5532 - val_accuracy: 0.6780\n",
            "Epoch 285/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9943\n",
            "Epoch 285: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 5.4333 - val_accuracy: 0.5795\n",
            "Epoch 286/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9877\n",
            "Epoch 286: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0302 - accuracy: 0.9877 - val_loss: 4.8673 - val_accuracy: 0.5682\n",
            "Epoch 287/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9886\n",
            "Epoch 287: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0546 - accuracy: 0.9886 - val_loss: 5.3947 - val_accuracy: 0.5644\n",
            "Epoch 288/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9773\n",
            "Epoch 288: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0547 - accuracy: 0.9773 - val_loss: 3.7045 - val_accuracy: 0.6326\n",
            "Epoch 289/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9754\n",
            "Epoch 289: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0737 - accuracy: 0.9754 - val_loss: 2.0779 - val_accuracy: 0.6553\n",
            "Epoch 290/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9877\n",
            "Epoch 290: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0307 - accuracy: 0.9877 - val_loss: 1.7518 - val_accuracy: 0.7348\n",
            "Epoch 291/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9896\n",
            "Epoch 291: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0299 - accuracy: 0.9896 - val_loss: 1.9115 - val_accuracy: 0.7311\n",
            "Epoch 292/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9877\n",
            "Epoch 292: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0303 - accuracy: 0.9877 - val_loss: 2.0142 - val_accuracy: 0.6932\n",
            "Epoch 293/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9848\n",
            "Epoch 293: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0419 - accuracy: 0.9848 - val_loss: 2.7920 - val_accuracy: 0.6515\n",
            "Epoch 294/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9896\n",
            "Epoch 294: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0449 - accuracy: 0.9896 - val_loss: 3.0206 - val_accuracy: 0.5871\n",
            "Epoch 295/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.9896\n",
            "Epoch 295: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0380 - accuracy: 0.9896 - val_loss: 2.1016 - val_accuracy: 0.6705\n",
            "Epoch 296/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9934\n",
            "Epoch 296: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.0302 - accuracy: 0.9934 - val_loss: 1.4512 - val_accuracy: 0.7348\n",
            "Epoch 297/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9915\n",
            "Epoch 297: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0218 - accuracy: 0.9915 - val_loss: 1.5629 - val_accuracy: 0.7311\n",
            "Epoch 298/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9877\n",
            "Epoch 298: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 1.8846 - val_accuracy: 0.7159\n",
            "Epoch 299/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9848\n",
            "Epoch 299: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0437 - accuracy: 0.9848 - val_loss: 1.9296 - val_accuracy: 0.6705\n",
            "Epoch 300/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9896\n",
            "Epoch 300: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0453 - accuracy: 0.9896 - val_loss: 1.4383 - val_accuracy: 0.7235\n",
            "Epoch 301/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9924\n",
            "Epoch 301: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 2.3409 - val_accuracy: 0.6326\n",
            "Epoch 302/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9934\n",
            "Epoch 302: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 5.6245 - val_accuracy: 0.4848\n",
            "Epoch 303/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9924\n",
            "Epoch 303: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 5.8125 - val_accuracy: 0.4697\n",
            "Epoch 304/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 0.9924\n",
            "Epoch 304: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 3.4291 - val_accuracy: 0.5833\n",
            "Epoch 305/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9905\n",
            "Epoch 305: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0337 - accuracy: 0.9905 - val_loss: 2.0445 - val_accuracy: 0.7121\n",
            "Epoch 306/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9877\n",
            "Epoch 306: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0578 - accuracy: 0.9877 - val_loss: 2.0921 - val_accuracy: 0.6667\n",
            "Epoch 307/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9924\n",
            "Epoch 307: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 2.0703 - val_accuracy: 0.6894\n",
            "Epoch 308/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9877\n",
            "Epoch 308: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 1.8030 - val_accuracy: 0.7311\n",
            "Epoch 309/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9943\n",
            "Epoch 309: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0397 - accuracy: 0.9943 - val_loss: 2.0823 - val_accuracy: 0.7121\n",
            "Epoch 310/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9886\n",
            "Epoch 310: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0289 - accuracy: 0.9886 - val_loss: 1.8812 - val_accuracy: 0.7083\n",
            "Epoch 311/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9924\n",
            "Epoch 311: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0208 - accuracy: 0.9924 - val_loss: 1.5336 - val_accuracy: 0.7235\n",
            "Epoch 312/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9905\n",
            "Epoch 312: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0215 - accuracy: 0.9905 - val_loss: 1.3337 - val_accuracy: 0.7462\n",
            "Epoch 313/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9943\n",
            "Epoch 313: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0128 - accuracy: 0.9943 - val_loss: 1.5899 - val_accuracy: 0.7500\n",
            "Epoch 314/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9934\n",
            "Epoch 314: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0160 - accuracy: 0.9934 - val_loss: 2.0435 - val_accuracy: 0.6780\n",
            "Epoch 315/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9924\n",
            "Epoch 315: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 1.9058 - val_accuracy: 0.7159\n",
            "Epoch 316/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9915\n",
            "Epoch 316: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0194 - accuracy: 0.9915 - val_loss: 1.5616 - val_accuracy: 0.7538\n",
            "Epoch 317/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9972\n",
            "Epoch 317: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0152 - accuracy: 0.9972 - val_loss: 1.8280 - val_accuracy: 0.7462\n",
            "Epoch 318/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9915\n",
            "Epoch 318: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0168 - accuracy: 0.9915 - val_loss: 2.3089 - val_accuracy: 0.6780\n",
            "Epoch 319/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9953\n",
            "Epoch 319: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0110 - accuracy: 0.9953 - val_loss: 1.8398 - val_accuracy: 0.7159\n",
            "Epoch 320/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9981\n",
            "Epoch 320: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 2.0326 - val_accuracy: 0.6818\n",
            "Epoch 321/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9962\n",
            "Epoch 321: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 1.9212 - val_accuracy: 0.6818\n",
            "Epoch 322/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9953\n",
            "Epoch 322: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0105 - accuracy: 0.9953 - val_loss: 1.8336 - val_accuracy: 0.7121\n",
            "Epoch 323/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9934\n",
            "Epoch 323: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0162 - accuracy: 0.9934 - val_loss: 2.4445 - val_accuracy: 0.6780\n",
            "Epoch 324/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9943\n",
            "Epoch 324: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 1.8330 - val_accuracy: 0.7159\n",
            "Epoch 325/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9972\n",
            "Epoch 325: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0155 - accuracy: 0.9972 - val_loss: 1.2910 - val_accuracy: 0.7841\n",
            "Epoch 326/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9934\n",
            "Epoch 326: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 2.5549 - val_accuracy: 0.6818\n",
            "Epoch 327/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9972\n",
            "Epoch 327: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 2.5481 - val_accuracy: 0.7121\n",
            "Epoch 328/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9962\n",
            "Epoch 328: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0097 - accuracy: 0.9962 - val_loss: 2.5870 - val_accuracy: 0.6667\n",
            "Epoch 329/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9962\n",
            "Epoch 329: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0073 - accuracy: 0.9962 - val_loss: 1.8249 - val_accuracy: 0.7121\n",
            "Epoch 330/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9943\n",
            "Epoch 330: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 1.5895 - val_accuracy: 0.7424\n",
            "Epoch 331/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9877\n",
            "Epoch 331: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0408 - accuracy: 0.9877 - val_loss: 1.8220 - val_accuracy: 0.7197\n",
            "Epoch 332/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9886\n",
            "Epoch 332: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0382 - accuracy: 0.9886 - val_loss: 2.1534 - val_accuracy: 0.7273\n",
            "Epoch 333/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9943\n",
            "Epoch 333: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 1.8540 - val_accuracy: 0.7159\n",
            "Epoch 334/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9953\n",
            "Epoch 334: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0114 - accuracy: 0.9953 - val_loss: 1.8874 - val_accuracy: 0.7159\n",
            "Epoch 335/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9953\n",
            "Epoch 335: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0199 - accuracy: 0.9953 - val_loss: 1.8546 - val_accuracy: 0.6932\n",
            "Epoch 336/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9858\n",
            "Epoch 336: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0262 - accuracy: 0.9858 - val_loss: 1.6843 - val_accuracy: 0.7197\n",
            "Epoch 337/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9915\n",
            "Epoch 337: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0224 - accuracy: 0.9915 - val_loss: 1.3052 - val_accuracy: 0.7576\n",
            "Epoch 338/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9943\n",
            "Epoch 338: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0150 - accuracy: 0.9943 - val_loss: 2.3968 - val_accuracy: 0.6894\n",
            "Epoch 339/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9934\n",
            "Epoch 339: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0122 - accuracy: 0.9934 - val_loss: 1.8852 - val_accuracy: 0.7083\n",
            "Epoch 340/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9943\n",
            "Epoch 340: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0104 - accuracy: 0.9943 - val_loss: 2.2469 - val_accuracy: 0.6818\n",
            "Epoch 341/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9953\n",
            "Epoch 341: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0207 - accuracy: 0.9953 - val_loss: 2.1615 - val_accuracy: 0.7008\n",
            "Epoch 342/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9934\n",
            "Epoch 342: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 1.9598 - val_accuracy: 0.7083\n",
            "Epoch 343/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9924\n",
            "Epoch 343: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0256 - accuracy: 0.9924 - val_loss: 2.3073 - val_accuracy: 0.6742\n",
            "Epoch 344/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9981\n",
            "Epoch 344: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 2.0847 - val_accuracy: 0.6932\n",
            "Epoch 345/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9915\n",
            "Epoch 345: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0357 - accuracy: 0.9915 - val_loss: 1.5086 - val_accuracy: 0.7348\n",
            "Epoch 346/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9924\n",
            "Epoch 346: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0277 - accuracy: 0.9924 - val_loss: 1.8167 - val_accuracy: 0.7424\n",
            "Epoch 347/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9943\n",
            "Epoch 347: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 2.9139 - val_accuracy: 0.7235\n",
            "Epoch 348/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9943\n",
            "Epoch 348: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 3.0361 - val_accuracy: 0.6364\n",
            "Epoch 349/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9905\n",
            "Epoch 349: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0201 - accuracy: 0.9905 - val_loss: 2.0646 - val_accuracy: 0.7197\n",
            "Epoch 350/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9915\n",
            "Epoch 350: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0304 - accuracy: 0.9915 - val_loss: 1.8531 - val_accuracy: 0.7083\n",
            "Epoch 351/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9886\n",
            "Epoch 351: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 1.3313 - val_accuracy: 0.7538\n",
            "Epoch 352/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9877\n",
            "Epoch 352: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 1.7213 - val_accuracy: 0.7500\n",
            "Epoch 353/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9886\n",
            "Epoch 353: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0279 - accuracy: 0.9886 - val_loss: 1.4018 - val_accuracy: 0.7576\n",
            "Epoch 354/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9943\n",
            "Epoch 354: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0109 - accuracy: 0.9943 - val_loss: 1.7396 - val_accuracy: 0.7424\n",
            "Epoch 355/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9953\n",
            "Epoch 355: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 1.5200 - val_accuracy: 0.7462\n",
            "Epoch 356/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9934\n",
            "Epoch 356: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 1.4442 - val_accuracy: 0.7121\n",
            "Epoch 357/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9934\n",
            "Epoch 357: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0163 - accuracy: 0.9934 - val_loss: 1.7815 - val_accuracy: 0.7235\n",
            "Epoch 358/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9981\n",
            "Epoch 358: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 2.2005 - val_accuracy: 0.6780\n",
            "Epoch 359/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9943\n",
            "Epoch 359: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 2.0020 - val_accuracy: 0.7311\n",
            "Epoch 360/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9962\n",
            "Epoch 360: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0256 - accuracy: 0.9962 - val_loss: 1.5208 - val_accuracy: 0.7689\n",
            "Epoch 361/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9943\n",
            "Epoch 361: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0376 - accuracy: 0.9943 - val_loss: 1.5703 - val_accuracy: 0.7462\n",
            "Epoch 362/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9877\n",
            "Epoch 362: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0327 - accuracy: 0.9877 - val_loss: 2.7155 - val_accuracy: 0.6780\n",
            "Epoch 363/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9858\n",
            "Epoch 363: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0387 - accuracy: 0.9858 - val_loss: 14.7839 - val_accuracy: 0.3068\n",
            "Epoch 364/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9924\n",
            "Epoch 364: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 4.2339 - val_accuracy: 0.5758\n",
            "Epoch 365/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9934\n",
            "Epoch 365: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0127 - accuracy: 0.9934 - val_loss: 2.1526 - val_accuracy: 0.6553\n",
            "Epoch 366/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9943\n",
            "Epoch 366: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0311 - accuracy: 0.9943 - val_loss: 1.6419 - val_accuracy: 0.7386\n",
            "Epoch 367/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9934\n",
            "Epoch 367: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0177 - accuracy: 0.9934 - val_loss: 1.3672 - val_accuracy: 0.7348\n",
            "Epoch 368/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9962\n",
            "Epoch 368: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0222 - accuracy: 0.9962 - val_loss: 1.5206 - val_accuracy: 0.7197\n",
            "Epoch 369/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9962\n",
            "Epoch 369: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 1.8924 - val_accuracy: 0.7197\n",
            "Epoch 370/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9981\n",
            "Epoch 370: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 1.9384 - val_accuracy: 0.7386\n",
            "Epoch 371/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9905\n",
            "Epoch 371: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0169 - accuracy: 0.9905 - val_loss: 2.4964 - val_accuracy: 0.6970\n",
            "Epoch 372/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9905\n",
            "Epoch 372: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 2.3353 - val_accuracy: 0.6932\n",
            "Epoch 373/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9953\n",
            "Epoch 373: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 2.0797 - val_accuracy: 0.7083\n",
            "Epoch 374/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9943\n",
            "Epoch 374: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0100 - accuracy: 0.9943 - val_loss: 1.7281 - val_accuracy: 0.7083\n",
            "Epoch 375/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9962\n",
            "Epoch 375: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0074 - accuracy: 0.9962 - val_loss: 1.5278 - val_accuracy: 0.7235\n",
            "Epoch 376/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9924\n",
            "Epoch 376: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 1.3614 - val_accuracy: 0.7727\n",
            "Epoch 377/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9924\n",
            "Epoch 377: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0262 - accuracy: 0.9924 - val_loss: 4.7946 - val_accuracy: 0.5152\n",
            "Epoch 378/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9943\n",
            "Epoch 378: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 3.1727 - val_accuracy: 0.6288\n",
            "Epoch 379/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.9886\n",
            "Epoch 379: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0347 - accuracy: 0.9886 - val_loss: 1.8772 - val_accuracy: 0.7159\n",
            "Epoch 380/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9934\n",
            "Epoch 380: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 1.7081 - val_accuracy: 0.7273\n",
            "Epoch 381/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9934\n",
            "Epoch 381: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0253 - accuracy: 0.9934 - val_loss: 1.6861 - val_accuracy: 0.7386\n",
            "Epoch 382/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9934\n",
            "Epoch 382: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0247 - accuracy: 0.9934 - val_loss: 1.5485 - val_accuracy: 0.7197\n",
            "Epoch 383/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972\n",
            "Epoch 383: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0097 - accuracy: 0.9972 - val_loss: 1.7604 - val_accuracy: 0.7500\n",
            "Epoch 384/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9953\n",
            "Epoch 384: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0233 - accuracy: 0.9953 - val_loss: 2.2744 - val_accuracy: 0.6970\n",
            "Epoch 385/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9962\n",
            "Epoch 385: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0087 - accuracy: 0.9962 - val_loss: 1.8692 - val_accuracy: 0.7614\n",
            "Epoch 386/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9962\n",
            "Epoch 386: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 1.8383 - val_accuracy: 0.7462\n",
            "Epoch 387/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9962\n",
            "Epoch 387: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0100 - accuracy: 0.9962 - val_loss: 1.8145 - val_accuracy: 0.7386\n",
            "Epoch 388/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9953\n",
            "Epoch 388: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 1.7878 - val_accuracy: 0.7159\n",
            "Epoch 389/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9934\n",
            "Epoch 389: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0272 - accuracy: 0.9934 - val_loss: 2.0942 - val_accuracy: 0.6970\n",
            "Epoch 390/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9915\n",
            "Epoch 390: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0171 - accuracy: 0.9915 - val_loss: 3.0273 - val_accuracy: 0.6439\n",
            "Epoch 391/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9934\n",
            "Epoch 391: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0259 - accuracy: 0.9934 - val_loss: 2.3351 - val_accuracy: 0.6629\n",
            "Epoch 392/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9972\n",
            "Epoch 392: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 1.6343 - val_accuracy: 0.7197\n",
            "Epoch 393/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9905\n",
            "Epoch 393: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 2.2383 - val_accuracy: 0.6970\n",
            "Epoch 394/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9915\n",
            "Epoch 394: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 2.0840 - val_accuracy: 0.7083\n",
            "Epoch 395/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9981\n",
            "Epoch 395: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 2.2647 - val_accuracy: 0.6932\n",
            "Epoch 396/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9962\n",
            "Epoch 396: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0181 - accuracy: 0.9962 - val_loss: 1.5919 - val_accuracy: 0.7462\n",
            "Epoch 397/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9953\n",
            "Epoch 397: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 1.8579 - val_accuracy: 0.7500\n",
            "Epoch 398/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9962\n",
            "Epoch 398: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 2.5213 - val_accuracy: 0.6705\n",
            "Epoch 399/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9934\n",
            "Epoch 399: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0128 - accuracy: 0.9934 - val_loss: 3.8415 - val_accuracy: 0.5758\n",
            "Epoch 400/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9953\n",
            "Epoch 400: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 2.5694 - val_accuracy: 0.6288\n",
            "Epoch 401/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9962\n",
            "Epoch 401: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 3.6148 - val_accuracy: 0.6098\n",
            "Epoch 402/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9924\n",
            "Epoch 402: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 2.4035 - val_accuracy: 0.6667\n",
            "Epoch 403/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981\n",
            "Epoch 403: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.8877 - val_accuracy: 0.7197\n",
            "Epoch 404/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9943\n",
            "Epoch 404: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0127 - accuracy: 0.9943 - val_loss: 3.8821 - val_accuracy: 0.6061\n",
            "Epoch 405/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9962\n",
            "Epoch 405: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0067 - accuracy: 0.9962 - val_loss: 2.5025 - val_accuracy: 0.6742\n",
            "Epoch 406/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9924\n",
            "Epoch 406: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0348 - accuracy: 0.9924 - val_loss: 3.1520 - val_accuracy: 0.6061\n",
            "Epoch 407/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9953\n",
            "Epoch 407: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0129 - accuracy: 0.9953 - val_loss: 1.8426 - val_accuracy: 0.7083\n",
            "Epoch 408/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9934\n",
            "Epoch 408: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0432 - accuracy: 0.9934 - val_loss: 1.1461 - val_accuracy: 0.7765\n",
            "Epoch 409/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9962\n",
            "Epoch 409: val_accuracy did not improve from 0.79545\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 1.7515 - val_accuracy: 0.7500\n",
            "Epoch 410/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9953\n",
            "Epoch 410: val_accuracy improved from 0.79545 to 0.79924, saving model to Emotions-weights-410-0.7992.h5\n",
            "33/33 [==============================] - 3s 96ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 1.3672 - val_accuracy: 0.7992\n",
            "Epoch 411/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9962\n",
            "Epoch 411: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.4692 - val_accuracy: 0.7727\n",
            "Epoch 412/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9962\n",
            "Epoch 412: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 1.6798 - val_accuracy: 0.7614\n",
            "Epoch 413/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9962\n",
            "Epoch 413: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0179 - accuracy: 0.9962 - val_loss: 1.5713 - val_accuracy: 0.7576\n",
            "Epoch 414/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9962\n",
            "Epoch 414: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0051 - accuracy: 0.9962 - val_loss: 1.6971 - val_accuracy: 0.7462\n",
            "Epoch 415/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9981\n",
            "Epoch 415: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 1.5893 - val_accuracy: 0.7500\n",
            "Epoch 416/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9972\n",
            "Epoch 416: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 1.7022 - val_accuracy: 0.7803\n",
            "Epoch 417/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9934\n",
            "Epoch 417: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0146 - accuracy: 0.9934 - val_loss: 1.8696 - val_accuracy: 0.7500\n",
            "Epoch 418/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981\n",
            "Epoch 418: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.8323 - val_accuracy: 0.7500\n",
            "Epoch 419/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9972\n",
            "Epoch 419: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 1.6621 - val_accuracy: 0.7462\n",
            "Epoch 420/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9943\n",
            "Epoch 420: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0220 - accuracy: 0.9943 - val_loss: 2.1665 - val_accuracy: 0.7159\n",
            "Epoch 421/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9962\n",
            "Epoch 421: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 2.4729 - val_accuracy: 0.6553\n",
            "Epoch 422/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9953\n",
            "Epoch 422: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0097 - accuracy: 0.9953 - val_loss: 2.1069 - val_accuracy: 0.6894\n",
            "Epoch 423/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 423: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.8157 - val_accuracy: 0.7311\n",
            "Epoch 424/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9934\n",
            "Epoch 424: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0182 - accuracy: 0.9934 - val_loss: 2.1524 - val_accuracy: 0.6856\n",
            "Epoch 425/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9981\n",
            "Epoch 425: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 1.9589 - val_accuracy: 0.7311\n",
            "Epoch 426/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9953\n",
            "Epoch 426: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0112 - accuracy: 0.9953 - val_loss: 1.5649 - val_accuracy: 0.7576\n",
            "Epoch 427/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9934\n",
            "Epoch 427: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0174 - accuracy: 0.9934 - val_loss: 2.1468 - val_accuracy: 0.6742\n",
            "Epoch 428/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9962\n",
            "Epoch 428: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0093 - accuracy: 0.9962 - val_loss: 1.8396 - val_accuracy: 0.7311\n",
            "Epoch 429/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
            "Epoch 429: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.7619 - val_accuracy: 0.7500\n",
            "Epoch 430/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
            "Epoch 430: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.7227 - val_accuracy: 0.7500\n",
            "Epoch 431/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9924\n",
            "Epoch 431: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 2.4885 - val_accuracy: 0.6742\n",
            "Epoch 432/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9934\n",
            "Epoch 432: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0127 - accuracy: 0.9934 - val_loss: 1.9611 - val_accuracy: 0.7045\n",
            "Epoch 433/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9962\n",
            "Epoch 433: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0081 - accuracy: 0.9962 - val_loss: 1.7877 - val_accuracy: 0.7121\n",
            "Epoch 434/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9953\n",
            "Epoch 434: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 1.8177 - val_accuracy: 0.7197\n",
            "Epoch 435/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9915\n",
            "Epoch 435: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0374 - accuracy: 0.9915 - val_loss: 2.1475 - val_accuracy: 0.6553\n",
            "Epoch 436/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9934\n",
            "Epoch 436: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0453 - accuracy: 0.9934 - val_loss: 1.9328 - val_accuracy: 0.7121\n",
            "Epoch 437/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9905\n",
            "Epoch 437: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0225 - accuracy: 0.9905 - val_loss: 1.3789 - val_accuracy: 0.7652\n",
            "Epoch 438/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9953\n",
            "Epoch 438: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 1.3305 - val_accuracy: 0.7727\n",
            "Epoch 439/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 439: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 1.4741 - val_accuracy: 0.7614\n",
            "Epoch 440/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9953\n",
            "Epoch 440: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0079 - accuracy: 0.9953 - val_loss: 1.6473 - val_accuracy: 0.7538\n",
            "Epoch 441/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9943\n",
            "Epoch 441: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0123 - accuracy: 0.9943 - val_loss: 1.9298 - val_accuracy: 0.7197\n",
            "Epoch 442/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9991\n",
            "Epoch 442: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 1.8779 - val_accuracy: 0.7159\n",
            "Epoch 443/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9972\n",
            "Epoch 443: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 1.5184 - val_accuracy: 0.7424\n",
            "Epoch 444/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9972\n",
            "Epoch 444: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 1.4552 - val_accuracy: 0.7652\n",
            "Epoch 445/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9962\n",
            "Epoch 445: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0081 - accuracy: 0.9962 - val_loss: 1.5327 - val_accuracy: 0.7803\n",
            "Epoch 446/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9972\n",
            "Epoch 446: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 90ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 1.5658 - val_accuracy: 0.7652\n",
            "Epoch 447/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9962\n",
            "Epoch 447: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0072 - accuracy: 0.9962 - val_loss: 1.4977 - val_accuracy: 0.7348\n",
            "Epoch 448/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9953\n",
            "Epoch 448: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 1.9099 - val_accuracy: 0.7235\n",
            "Epoch 449/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9972\n",
            "Epoch 449: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0067 - accuracy: 0.9972 - val_loss: 2.3749 - val_accuracy: 0.7311\n",
            "Epoch 450/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9981\n",
            "Epoch 450: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0040 - accuracy: 0.9981 - val_loss: 1.9252 - val_accuracy: 0.7462\n",
            "Epoch 451/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9991\n",
            "Epoch 451: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0017 - accuracy: 0.9991 - val_loss: 1.8353 - val_accuracy: 0.7614\n",
            "Epoch 452/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9943\n",
            "Epoch 452: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 2.0434 - val_accuracy: 0.7311\n",
            "Epoch 453/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9962\n",
            "Epoch 453: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0083 - accuracy: 0.9962 - val_loss: 2.1113 - val_accuracy: 0.7045\n",
            "Epoch 454/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9934\n",
            "Epoch 454: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0107 - accuracy: 0.9934 - val_loss: 1.5670 - val_accuracy: 0.7462\n",
            "Epoch 455/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9972\n",
            "Epoch 455: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 93ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 1.6925 - val_accuracy: 0.7652\n",
            "Epoch 456/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9905\n",
            "Epoch 456: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0214 - accuracy: 0.9905 - val_loss: 1.4831 - val_accuracy: 0.7803\n",
            "Epoch 457/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9943\n",
            "Epoch 457: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0108 - accuracy: 0.9943 - val_loss: 2.3933 - val_accuracy: 0.7045\n",
            "Epoch 458/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9991\n",
            "Epoch 458: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 2.7415 - val_accuracy: 0.7159\n",
            "Epoch 459/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9924\n",
            "Epoch 459: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0204 - accuracy: 0.9924 - val_loss: 2.0739 - val_accuracy: 0.7235\n",
            "Epoch 460/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9953\n",
            "Epoch 460: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0102 - accuracy: 0.9953 - val_loss: 2.2261 - val_accuracy: 0.7045\n",
            "Epoch 461/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 461: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 1.5166 - val_accuracy: 0.7424\n",
            "Epoch 462/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9991\n",
            "Epoch 462: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 91ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 2.7022 - val_accuracy: 0.7008\n",
            "Epoch 463/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9905\n",
            "Epoch 463: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 1.5085 - val_accuracy: 0.7121\n",
            "Epoch 464/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9943\n",
            "Epoch 464: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0083 - accuracy: 0.9943 - val_loss: 1.9583 - val_accuracy: 0.7197\n",
            "Epoch 465/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9962\n",
            "Epoch 465: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0100 - accuracy: 0.9962 - val_loss: 2.0002 - val_accuracy: 0.6894\n",
            "Epoch 466/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9953\n",
            "Epoch 466: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 2.7093 - val_accuracy: 0.6629\n",
            "Epoch 467/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9924\n",
            "Epoch 467: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0175 - accuracy: 0.9924 - val_loss: 1.5805 - val_accuracy: 0.7273\n",
            "Epoch 468/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9962\n",
            "Epoch 468: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 1.4616 - val_accuracy: 0.7386\n",
            "Epoch 469/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9905\n",
            "Epoch 469: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0487 - accuracy: 0.9905 - val_loss: 2.6997 - val_accuracy: 0.5985\n",
            "Epoch 470/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9877\n",
            "Epoch 470: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0350 - accuracy: 0.9877 - val_loss: 3.6236 - val_accuracy: 0.5682\n",
            "Epoch 471/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9943\n",
            "Epoch 471: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0144 - accuracy: 0.9943 - val_loss: 7.2442 - val_accuracy: 0.4318\n",
            "Epoch 472/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9953\n",
            "Epoch 472: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0120 - accuracy: 0.9953 - val_loss: 2.5106 - val_accuracy: 0.5985\n",
            "Epoch 473/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9953\n",
            "Epoch 473: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 3.1835 - val_accuracy: 0.6098\n",
            "Epoch 474/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9991\n",
            "Epoch 474: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 2.5594 - val_accuracy: 0.6553\n",
            "Epoch 475/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9943\n",
            "Epoch 475: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0240 - accuracy: 0.9943 - val_loss: 1.6715 - val_accuracy: 0.6932\n",
            "Epoch 476/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9962\n",
            "Epoch 476: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 2.0512 - val_accuracy: 0.7235\n",
            "Epoch 477/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9972\n",
            "Epoch 477: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 1.6794 - val_accuracy: 0.7803\n",
            "Epoch 478/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9953\n",
            "Epoch 478: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0102 - accuracy: 0.9953 - val_loss: 1.4891 - val_accuracy: 0.7841\n",
            "Epoch 479/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9962\n",
            "Epoch 479: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0076 - accuracy: 0.9962 - val_loss: 1.6647 - val_accuracy: 0.7652\n",
            "Epoch 480/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9962\n",
            "Epoch 480: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0070 - accuracy: 0.9962 - val_loss: 1.6853 - val_accuracy: 0.7462\n",
            "Epoch 481/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9943\n",
            "Epoch 481: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0231 - accuracy: 0.9943 - val_loss: 2.2343 - val_accuracy: 0.6856\n",
            "Epoch 482/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9943\n",
            "Epoch 482: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 1.4358 - val_accuracy: 0.7348\n",
            "Epoch 483/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9972\n",
            "Epoch 483: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 1.4259 - val_accuracy: 0.7348\n",
            "Epoch 484/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9943\n",
            "Epoch 484: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 1.1570 - val_accuracy: 0.7614\n",
            "Epoch 485/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9934\n",
            "Epoch 485: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0172 - accuracy: 0.9934 - val_loss: 1.4874 - val_accuracy: 0.7348\n",
            "Epoch 486/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9943\n",
            "Epoch 486: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0264 - accuracy: 0.9943 - val_loss: 3.5283 - val_accuracy: 0.6364\n",
            "Epoch 487/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9962\n",
            "Epoch 487: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.8222 - val_accuracy: 0.7235\n",
            "Epoch 488/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981\n",
            "Epoch 488: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 89ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 1.7699 - val_accuracy: 0.7273\n",
            "Epoch 489/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9962\n",
            "Epoch 489: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 1.4276 - val_accuracy: 0.7386\n",
            "Epoch 490/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9953\n",
            "Epoch 490: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 1.6692 - val_accuracy: 0.7045\n",
            "Epoch 491/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9953\n",
            "Epoch 491: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0118 - accuracy: 0.9953 - val_loss: 1.8415 - val_accuracy: 0.7159\n",
            "Epoch 492/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9962\n",
            "Epoch 492: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0360 - accuracy: 0.9962 - val_loss: 2.0769 - val_accuracy: 0.7159\n",
            "Epoch 493/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9953\n",
            "Epoch 493: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 2.4320 - val_accuracy: 0.6364\n",
            "Epoch 494/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9943\n",
            "Epoch 494: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0150 - accuracy: 0.9943 - val_loss: 1.5213 - val_accuracy: 0.7235\n",
            "Epoch 495/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9981\n",
            "Epoch 495: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 2.3758 - val_accuracy: 0.6932\n",
            "Epoch 496/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9943\n",
            "Epoch 496: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 92ms/step - loss: 0.0149 - accuracy: 0.9943 - val_loss: 1.4695 - val_accuracy: 0.7348\n",
            "Epoch 497/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9972\n",
            "Epoch 497: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 87ms/step - loss: 0.0065 - accuracy: 0.9972 - val_loss: 1.5463 - val_accuracy: 0.7273\n",
            "Epoch 498/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9962\n",
            "Epoch 498: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 1.2797 - val_accuracy: 0.7652\n",
            "Epoch 499/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981\n",
            "Epoch 499: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 1.3947 - val_accuracy: 0.7803\n",
            "Epoch 500/500\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9943\n",
            "Epoch 500: val_accuracy did not improve from 0.79924\n",
            "33/33 [==============================] - 3s 88ms/step - loss: 0.0095 - accuracy: 0.9943 - val_loss: 1.3549 - val_accuracy: 0.7841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open('Emotions_config.json', 'w') as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "metadata": {
        "id": "p0ffeV1iBr19"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show original Image\n",
        "i = randint(0,len(y_test_original)-1)\n",
        "print (\"picture \",i)\n",
        "print(\"actual:\", y_test_original[i])\n",
        "plt.imshow(x_test_original[i])\n",
        "\n",
        "# Sample Predict\n",
        "sample = np.array([x_test[i]])\n",
        "predictions = np.argmax(model.predict(sample), axis=-1)\n",
        "print(\"predictions:\", predictions)\n",
        "print(\"predictions label:\", x_label[int(predictions)])"
      ],
      "metadata": {
        "id": "CFOXlFftDpiY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "c9d796ea-d649-43b3-9cc7-c311fc6f4dc3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "picture  141\n",
            "actual: [0 0 0 1]\n",
            "predictions: [3]\n",
            "predictions label: Surprise\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphs of accuracy\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.grid(True)\n",
        "#plt.gca().set_ylim(0,1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','validation'],loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P4942ZUyDzHX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "514429fa-7ef9-4cff-db9f-a0591b408b68"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}